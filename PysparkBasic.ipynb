{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d292d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "\n",
    "#create spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ef0a1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-8PT3G6R:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x269c1996510>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df054bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ala</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ble</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cos</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name   age\n",
       "0   Ala   10\n",
       "1   Ble   20\n",
       "2   Cos   30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('Book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "163ea5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.read_csv('Book1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce2759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset through spark\n",
    "df_pyspark=spark.read.csv('Book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33afd277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ebbcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|  _c0|_c1|\n",
      "+-----+---+\n",
      "|Name |age|\n",
      "|  Ala| 10|\n",
      "|  Ble| 20|\n",
      "|  Cos| 30|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b76bb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name : string, age: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first row as header\n",
    "df_pyspark=spark.read.option('header','true').csv('Book1.csv')\n",
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49c087e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|Name |age|\n",
      "+-----+---+\n",
      "|  Ala| 10|\n",
      "|  Ble| 20|\n",
      "|  Cos| 30|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.option('header','true').csv('Book1.csv').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d4c4025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7c6ddd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name ='Ala', age='10'),\n",
       " Row(Name ='Ble', age='20'),\n",
       " Row(Name ='Cos', age='30')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e106fe32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name : string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f63bf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name ', 'age']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa1d28fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: string]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2258946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 10|\n",
      "| 20|\n",
      "| 30|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b526ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|Name |\n",
      "+---+-----+\n",
      "| 10|  Ala|\n",
      "| 20|  Ble|\n",
      "| 30|  Cos|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('age','Name ').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de4a6940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name ', 'string'), ('age', 'string')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccab5912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read again with proper datatype\n",
    "df_sparkk=spark.read.csv('Book1.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e41ec87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name ', 'string'), ('age', 'int')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sparkk.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75baf910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Name : string, age: string]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sparkk.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8aff3c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----+\n",
      "|summary|Name | age|\n",
      "+-------+-----+----+\n",
      "|  count|    3|   3|\n",
      "|   mean| null|20.0|\n",
      "| stddev| null|10.0|\n",
      "|    min|  Ala|  10|\n",
      "|    max|  Cos|  30|\n",
      "+-------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sparkk.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb5b4283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column (base on existing column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec4e6496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+\n",
      "|Name |age|Experience|\n",
      "+-----+---+----------+\n",
      "|  Ala| 10|         5|\n",
      "|  Ble| 20|        15|\n",
      "|  Cos| 30|        25|\n",
      "+-----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sparkk.withColumn('Experience',df_sparkk['age']-5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc341875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|Name |age|\n",
      "+-----+---+\n",
      "|  Ala| 10|\n",
      "|  Ble| 20|\n",
      "|  Cos| 30|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop column\n",
    "df_sparkk.drop('Experience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8fc7395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|New name|age|\n",
      "+--------+---+\n",
      "|     Ala| 10|\n",
      "|     Ble| 20|\n",
      "|     Cos| 30|\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rename\n",
    "df_sparkk.withColumnRenamed('Name ','New name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45102bc0",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2993f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark2=spark.read.csv('Book2.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01d94b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+\n",
      "|Name | age|Experience|Salary|\n",
      "+-----+----+----------+------+\n",
      "|  Ala|  10|         1| 30000|\n",
      "|  Ble|  20|         2| 25000|\n",
      "|  Cos|  30|         4| 20000|\n",
      "|  Dse|  40|         8| 18000|\n",
      "|  Eve|  50|         1| 22000|\n",
      "|  Far|  60|         2| 23000|\n",
      "|  Gor|null|      null| 40000|\n",
      "| null|  70|        10| 38000|\n",
      "| null|  80|      null|  null|\n",
      "+-----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31abf83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "|Name |age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|  Ala| 10|         1| 30000|\n",
      "|  Ble| 20|         2| 25000|\n",
      "|  Cos| 30|         4| 20000|\n",
      "|  Dse| 40|         8| 18000|\n",
      "|  Eve| 50|         1| 22000|\n",
      "|  Far| 60|         2| 23000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop any row contains null value\n",
    "df_pyspark2.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "121a7110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+----------+------+\n",
      "|        Name | age|Experience|Salary|\n",
      "+-------------+----+----------+------+\n",
      "|          Ala|  10|         1| 30000|\n",
      "|          Ble|  20|         2| 25000|\n",
      "|          Cos|  30|         4| 20000|\n",
      "|          Dse|  40|         8| 18000|\n",
      "|          Eve|  50|         1| 22000|\n",
      "|          Far|  60|         2| 23000|\n",
      "|          Gor|null|      null| 40000|\n",
      "|Missing value|  70|        10| 38000|\n",
      "|Missing value|  80|      null|  null|\n",
      "+-------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filling missing value\n",
    "df_pyspark2.na.fill('Missing value').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64a1c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill other null value with mean\n",
    "from pyspark.ml.feature import Imputer\n",
    "imputer=Imputer(\n",
    "                inputCols=['age','Experience','Salary'],\n",
    "                outputCols=[\"{}_imputed\".format(c) for c in ['age','Experience','Salary']]\n",
    "               ).setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "253fe930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+-----------+------------------+--------------+\n",
      "|Name | age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
      "+-----+----+----------+------+-----------+------------------+--------------+\n",
      "|  Ala|  10|         1| 30000|         10|                 1|         30000|\n",
      "|  Ble|  20|         2| 25000|         20|                 2|         25000|\n",
      "|  Cos|  30|         4| 20000|         30|                 4|         20000|\n",
      "|  Dse|  40|         8| 18000|         40|                 8|         18000|\n",
      "|  Eve|  50|         1| 22000|         50|                 1|         22000|\n",
      "|  Far|  60|         2| 23000|         60|                 2|         23000|\n",
      "|  Gor|null|      null| 40000|         45|                 4|         40000|\n",
      "| null|  70|        10| 38000|         70|                10|         38000|\n",
      "| null|  80|      null|  null|         80|                 4|         27000|\n",
      "+-----+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add imputation cols to df\n",
    "imputer.fit(df_pyspark2).transform(df_pyspark2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965987d",
   "metadata": {},
   "source": [
    "## Filter Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98097698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "|Name |age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|  Cos| 30|         4| 20000|\n",
      "|  Dse| 40|         8| 18000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark2.filter(\"Salary<=20000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "982f1726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "|age|Experience|\n",
      "+---+----------+\n",
      "| 30|         4|\n",
      "| 40|         8|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark2.filter(\"Salary<=20000\").select(['age','Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63d68ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "|Name |age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|  Dse| 40|         8| 18000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark2.filter((df_pyspark2['Salary']<=20000) & (df_pyspark2['Experience']>5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4547f559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+\n",
      "|Name | age|Experience|Salary|\n",
      "+-----+----+----------+------+\n",
      "|  Ala|  10|         1| 30000|\n",
      "|  Ble|  20|         2| 25000|\n",
      "|  Eve|  50|         1| 22000|\n",
      "|  Far|  60|         2| 23000|\n",
      "|  Gor|null|      null| 40000|\n",
      "| null|  70|        10| 38000|\n",
      "+-----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark2.filter(~(df_pyspark2['Salary']<=20000)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df4d95",
   "metadata": {},
   "source": [
    "## Group by & Aggregate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caf4ed41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|Name|Dep|Salary|\n",
      "+----+---+------+\n",
      "| Kri| DS| 10000|\n",
      "| Kri|IOT|  5000|\n",
      "| Mah| BD|  4000|\n",
      "| Kri| BD|  4000|\n",
      "| Mah| DS|  3000|\n",
      "| Sus| DS| 20000|\n",
      "| Sus|IOT| 10000|\n",
      "| Sus| BD|  5000|\n",
      "| Uny| DS| 10000|\n",
      "| Uny| BD|  2000|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark3=spark.read.csv('Book3.csv',header=True,inferSchema=True)\n",
    "df_pyspark3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aebe925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|Name|sum(Salary)|\n",
      "+----+-----------+\n",
      "| Kri|      19000|\n",
      "| Uny|      12000|\n",
      "| Sus|      35000|\n",
      "| Mah|       7000|\n",
      "+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Group by\n",
    "df_pyspark3.groupBy('Name').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29b0a5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "|Dep|avg(Salary)|\n",
      "+---+-----------+\n",
      "|IOT|     7500.0|\n",
      "| BD|     3750.0|\n",
      "| DS|    10750.0|\n",
      "+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark3.groupBy('Dep').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64febfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|      73000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# direct Aggr\n",
    "df_pyspark3.agg({'Salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c6f83",
   "metadata": {},
   "source": [
    "## Example of PysparkML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "865b1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "py_spark4=spark.read.csv('Book4.csv',header=True,inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d88dbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+------+\n",
      "|Name|age|Experience|Salary|\n",
      "+----+---+----------+------+\n",
      "| Ala| 31|        10| 30000|\n",
      "| Blc| 30|         8| 25000|\n",
      "| Clo| 29|         4| 20000|\n",
      "| Dre| 24|         3| 20000|\n",
      "| Eve| 21|         2| 15000|\n",
      "| Flo| 23|         1| 18000|\n",
      "+----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "py_spark4.show()\n",
    "# Use age & Exp to predict Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08e78d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the independencies\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler=VectorAssembler(inputCols=['age','Experience'],outputCol='AgeExp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "335e3f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=featureassembler.transform(py_spark4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d53ccc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+------+-----------+\n",
      "|Name|age|Experience|Salary|     AgeExp|\n",
      "+----+---+----------+------+-----------+\n",
      "| Ala| 31|        10| 30000|[31.0,10.0]|\n",
      "| Blc| 30|         8| 25000| [30.0,8.0]|\n",
      "| Clo| 29|         4| 20000| [29.0,4.0]|\n",
      "| Dre| 24|         3| 20000| [24.0,3.0]|\n",
      "| Eve| 21|         2| 15000| [21.0,2.0]|\n",
      "| Flo| 23|         1| 18000| [23.0,1.0]|\n",
      "+----+---+----------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6090608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|     AgeExp|Salary|\n",
      "+-----------+------+\n",
      "|[31.0,10.0]| 30000|\n",
      "| [30.0,8.0]| 25000|\n",
      "| [29.0,4.0]| 20000|\n",
      "| [24.0,3.0]| 20000|\n",
      "| [21.0,2.0]| 15000|\n",
      "| [23.0,1.0]| 18000|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finaldata=output.select('AgeExp','Salary')\n",
    "finaldata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "248b78b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LR model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "train_data,test_data=finaldata.randomSplit([0.75,0.25])\n",
    "regressor=LinearRegression(featuresCol='AgeExp',labelCol='Salary')\n",
    "regressor=regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad2a5d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DenseVector([1047.1859, 296.191]), -6839.1131324643975)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## coefficient & intercept\n",
    "regressor.coefficients,regressor.intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0498479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------------------+\n",
      "|    AgeExp|Salary|        prediction|\n",
      "+----------+------+------------------+\n",
      "|[29.0,4.0]| 20000|24714.042069358118|\n",
      "+----------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "pred_results=regressor.evaluate(test_data)\n",
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdd80137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4714.042069358118, 22222192.631678168)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# other parameter\n",
    "pred_results.meanAbsoluteError, pred_results.meanSquaredError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d80a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
